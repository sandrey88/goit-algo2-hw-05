# goit-algo2-hw-05

## Алгоритми роботи з великими даними

### Завдання 1. Перевірка унікальності паролів за допомогою фільтра Блума (passwords_uniqueness_bf.py)

**Результати виконання:**

```
Пароль 'password123' - вже використаний.
Пароль 'newpassword' - унікальний.
Пароль 'admin123' - вже використаний.
Пароль 'guest' - унікальний.
```

### Завдання 2. Порівняння продуктивності HyperLogLog із точним підрахунком унікальних елементів (hyperloglog_vs_counting.py)

hyperloglog.py - реалізація алгоритму HyperLogLog

**Примітка:** Для підрахунку унікальних IP-адрес використовується лише поле `remote_addr` з кожного рядка лог-файлу.

**Результати виконання:**

```
Завантажено 29553 IP-адрес.
Результати порівняння:
                            Точний підрахунок    HyperLogLog
Унікальні елементи                       28.0           28.0
Час виконання (сек.)                     0.00           0.05
```

**Висновок:**

- Для заданого набору даних (29553 записів) точний підрахунок через set працює дуже швидко та ефективно.
- HyperLogLog дає таку ж точність, але працює повільніше, оскільки на малих даних працює повільніше через додаткові обчислення при кожному додаванні елемента.
- HyperLogLog стає корисним на дуже великих наборах даних (мільйони унікальних значень), бо він використовує набагато менше пам’яті і дозволяє швидко оцінювати кількість унікальних елементів, не зберігаючи всі дані.
